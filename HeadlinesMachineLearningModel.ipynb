{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet P3\n",
    "## HeadlinesMachineLearningModel\n",
    "Ce notebook retrace les différentes étapes de création des modèles de machines learning avec le jeu de données des titres d'articles financiers\n",
    "\n",
    "`Auteur` : Romain Capocasale (INF3dlm-a)\n",
    "\n",
    "`Date` : 01.10.2019\n",
    "\n",
    "`Version de python` : 3.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import pickle\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "from gensim.utils import simple_preprocess\n",
    "from joblib import dump, load\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tools.TextProcessor import TextProcessor\n",
    "\n",
    "np.random.seed(42)# to make this notebook's output stable across runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chragement du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json('dataset/headlines_dataset/financialData.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyse du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>watching for bounce tomorrow</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>record number of passengers served in 2015</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>out $NFLX -.35</td>\n",
       "      <td>-0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Looking for a strong bounce Lunchtime rally co...</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Very intrigued with the technology and growth ...</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  sentiment\n",
       "0                      watching for bounce tomorrow       0.366\n",
       "1        record number of passengers served in 2015       0.638\n",
       "2                                    out $NFLX -.35      -0.494\n",
       "3  Looking for a strong bounce Lunchtime rally co...      0.460\n",
       "4  Very intrigued with the technology and growth ...      0.403"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2866 entries, 0 to 2865\n",
      "Data columns (total 2 columns):\n",
      "title        2866 non-null object\n",
      "sentiment    2866 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 44.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2866.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.391033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  2866.000000\n",
       "mean      0.079841\n",
       "std       0.391033\n",
       "min      -1.000000\n",
       "25%      -0.285000\n",
       "50%       0.206000\n",
       "75%       0.387000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données contient 2 colonnes :\n",
    "    - sentiment : le sentiment de la pharse, entre -1 pour negatif et 1 pour positif\n",
    "    - title : la phrase en question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Répartition des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data : 2866\n",
      "Number of positive data : 1756 (61.27%)\n",
      "Number of negative data : 1045 (36.462%)\n",
      "Number of neutral data : 65 (2.268%)\n",
      "Ratio positive/negative : 1.68\n"
     ]
    }
   ],
   "source": [
    "nb_pos, nb_neg, nb_ntr = len([sent for sent in dataset.sentiment if sent > 0]), len([sent for sent in dataset.sentiment if sent < 0]), len([sent for sent in dataset.sentiment if sent == 0])\n",
    "tot = len(dataset)\n",
    "print(\"Number of data : {}\".format(tot))\n",
    "print(\"Number of positive data : {} ({}%)\".format(nb_pos, round( nb_pos/tot*100, 3)))\n",
    "print(\"Number of negative data : {} ({}%)\".format(nb_neg, round( nb_neg/tot*100, 3)))\n",
    "print(\"Number of neutral data : {} ({}%)\".format(nb_ntr, round( nb_ntr/tot*100, 3)))\n",
    "print(\"Ratio positive/negative : {}\".format(round(nb_pos/nb_neg, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000018FC5792508>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'il y a plus de phrase avec un sentiment positif que négatif. On remarque également sur le graphe 2 pics, un pour les sentiments négatifs aux alentours de -0.40 et un pour les sentiment positif vers 0.40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Nombre de mot moyen par phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_by_sentence(sentences):\n",
    "    '''Compute the average of word in a sentence\n",
    "    sentence -- list of sentences\n",
    "    return -- average number of word by sentence\n",
    "    '''\n",
    "    nb_total_word = 0\n",
    "    for row in sentences:\n",
    "        nb_total_word += len(row.split())\n",
    "    return round(nb_total_word / len(sentences), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of word by sentence : 7.515\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of word by sentence : {}\".format(average_word_by_sentence(dataset['title'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of sentence')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_word_by_sentence = [len(x.split()) for x in dataset['title']]#count the number of word for each sentences\n",
    "\n",
    "plt.hist(num_word_by_sentence, bins=25)\n",
    "plt.title('Number of word by sentence', fontsize=20)\n",
    "plt.xlabel('Number of word', fontsize=14)\n",
    "plt.ylabel('Number of sentence', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que la moyenne de nombre de mot par phrase est de **7.515** et on peut voir sur le graphe la répartition du nombre de mot par phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Séparation des observation et des étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['title']\n",
    "y = dataset['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Séparation du jeu d'entrainement et jeu de test \n",
    "Le jeu d'entrainement est séparé en 2 parties, La première partie est le jeu d'entrainement qui sera utilisé pour la création du modèle d'analyse de sentiment. Le jeu de test sera lui utilisé pour tester la qualité des modèles évalués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Definition des méthode de calcul de score\n",
    "La méthode print_scores() permet de calculer la RMSE, la MAE et la précision à partir des vrai étiquettes et des étiquettes prédites. Il est également possible d'indiquer le seuil désiré, le seuil permet de definir pour une prédiction si elle doit considéré come positive ou négative. La méthode regression_score_to_classification() permet de transformer les étiquettes du format régression au format classification. Les étiquettes de -1 à seuil sont mise à 0 et celles de seuil à 1 sont mise à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_near_zero_values(y_test, y_pred, threshold):\n",
    "    '''As the classifier is here binary, on only keep the values between -1 and 0 not included and between 1 and 0 not included. \n",
    "    You must therefore delete the values at zero.Put in a list the indices of the values which are 0 and remove them from the 2 lists.\n",
    "        \n",
    "    y_test -- list of real value\n",
    "    y_pred -- list of predicted value\n",
    "    thrshold -- seuil\n",
    "    \n",
    "    return -- a tuple which contain y_test and y_pred without 0 values\n",
    "    '''\n",
    "    index_to_remove = []\n",
    "    i = 0\n",
    "    for test, pred in zip(y_test, y_pred):\n",
    "        if test == threshold or pred == threshold:\n",
    "            index_to_remove.append(i)\n",
    "        i+=1\n",
    "    y_test = [i for j, i in enumerate(y_test) if j not in index_to_remove]\n",
    "    y_pred = [i for j, i in enumerate(y_pred) if j not in index_to_remove]\n",
    "    return (y_test, y_pred)\n",
    "\n",
    "def regression_score_to_classification(labels, threshold):\n",
    "    '''Set to 0 regression prediction between -1 and thresold, set to 1 regression preiction between thresold and 1\n",
    "    Allow to pass from regression prediction to classification prediction\n",
    "    \n",
    "    labels -- list of regression score\n",
    "    thresold -- thresold\n",
    "    \n",
    "    return -- list of labels either 0 or 1\n",
    "    '''\n",
    "    \n",
    "    y_clf = []\n",
    "    for i, y in enumerate(labels):\n",
    "        if y <= threshold:\n",
    "            y_clf.append(0)\n",
    "        elif y > threshold:\n",
    "            y_clf.append(1)\n",
    "    return np.array(y_clf)\n",
    "        \n",
    "\n",
    "def print_scores(name, y_test, y_pred, threshold=0, show_classification_report=False):\n",
    "    '''Display the RMSE, MAE and accuracy for a model\n",
    "    \n",
    "    name -- name of the model\n",
    "    y_test -- true data\n",
    "    y_pred -- predicted data \n",
    "    threshold=0 -- threshold\n",
    "    show_classification_report=False -- display the score with sklearn.metrics.classification_report function\n",
    "    \n",
    "    '''\n",
    "    print(\"RMSE for {} : {}\".format(name, np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "    print(\"MAE for {} : {}\".format(name, metrics.mean_absolute_error(y_test, y_pred)))\n",
    "    \n",
    "    y_test, y_pred = remove_near_zero_values(y_test, y_pred, threshold)\n",
    "    \n",
    "    y_test_clf = regression_score_to_classification(y_test, threshold)\n",
    "    y_pred_clf = regression_score_to_classification(y_pred, threshold)\n",
    "    \n",
    "    print(\"Accuracy for {} : {}\".format(name, metrics.accuracy_score(y_test_clf, y_pred_clf)))\n",
    "    print(\"Recall for {} : {}\".format(name, metrics.recall_score(y_test_clf, y_pred_clf)))\n",
    "    print(\"Precision for {} : {}\".format(name, metrics.precision_score(y_test_clf, y_pred_clf)))\n",
    "    if show_classification_report:\n",
    "        print(metrics.classification_report(y_test_clf, y_pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Score de textblob et VADER\n",
    "Nous allons comparé le score de l'analyseur de sentiment de VADER(nltk) et textblob sur le jeu d'entrainement. Il est à noté que les phrases ne sont pas prétraité avant d'être envoyé aux analyseur de sentiment. En effet, ces 2 analyseur posséde leur propre méthode de prétraitement de texte. Les scores obtenus ici seront utilisé comme score de référence pour l'évaluation des futures modèles. Le but des futures modèles est de battre ces scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_textblob = []\n",
    "\n",
    "for x in X_test:\n",
    "    blob_analyser = TextBlob(x)\n",
    "    y_pred_textblob.append(blob_analyser.polarity)\n",
    "    \n",
    "y_pred_textblob = np.array(y_pred_textblob)\n",
    "print_scores('textblob', y_test, y_pred_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "y_pred_vader = []\n",
    "for x in X_test:\n",
    "    y_pred_vader.append(vader_analyser.polarity_scores(x)['compound'])\n",
    "\n",
    "y_pred_vader = np.array(y_pred_vader)\n",
    "print_scores('VADER', y_test, y_pred_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque ques ces analyseurs ont une RMSE et MAE assez haute. L'accuracy est quand à elle etonnamment haute. Cepandant on remarque que ces 2 analyseurs ont souvent tendances à prédire une polarité de 0. 364 zeros pour textblob et 282 pour vader. \n",
    "\n",
    "Comme la méthode qui transforme les scores de régression en classification supprime toutes les valeurs on se retrouve avec beaucoup de valeurs en moins. Par exemple pour textlob si on enelve 364 valeurs au 574 du jeu de test, il ne reste que 210 valeurs. Il est donc normal que ces analyseurs ai de bonne performance mais en réalité les performance sont plutot mauavaises. Ils ont tendances à predire trop de 0. Même remarque pour le rappel et la précision **Seul les scores RMSE et MAE doivent être pris en compte ici**.\n",
    "\n",
    "Si on teste les analyseurs sans retirer les phrases avec un sentiment de 0, on obtient l'exatitude suivante :\n",
    "* Textblob -> 0.517\n",
    "* Vader -> 0.548"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Traitement du texte\n",
    "## 7.1. Prétraitement avec Spacy\n",
    "\n",
    "Le traitement du texte est effectué avec la librairie spacy. La classe de prétraitement du teste se trouve dans : ``tools/TextProcessor``. La classe hérite de BaseEstimator et de TransformerMixin. Le fait d'heriter de ces 2 classes permettera d'inclure cette classe dans le pipeline sklearn. Différent paramétres pour le prétraitement du texte sont défini dans le constructeur. Le principale avantage de cette méthode est qu'elle se combine avec l'utilisation de la classe GridSearchCV() ou RandomSearch() qui permet de chercher les meilleurs hyper-parametrès pour un modèle.\n",
    "\n",
    "Pour le prétraitement, différentes processus sont effectués sur la phrase:\n",
    " * **Tokenisation** : consiste à découper la phrase en mot.\n",
    " * **Suppression des ``stop word``** : suppresion des mots comme ``the``, ``are``, etc. Ce paramétre est configurable via le constructeur\n",
    " * **Tagging et suppression de certains mots tagués** : le tagging consiste à detecter le type du mot comme par exemple ``nom``, ``adjectif``, ``verbe``, etc. Par la suite, il faut supprimer le type de mot que l'on ne veut pas garder dans la phrase. Actuellement, les verbes, adverbes, nom et adjectifs sont conservés. Ce paramétre est configurable via le constructeur.\n",
    " * **Taille du mot** : consiste à garder que les mots d'une certaines taille. Ce paramétre est configurable via le constructeur.\n",
    " * **Suppresion de la ponctuation** : suppresion des caractère comme ``!``, ``?``, etc.\n",
    " * **Lemmatisation** : consiste à ne garder que la racine des mots dans le but de réduire la taille du dictionnaire. Par exemple, les mots comme ``runs``, ``running`` seront transformer en ``run``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextProcessor(keep_only_good_word=False, remove_stop_word=True)\n",
    "X_train_pre_spacy = tp.transform(X_train)\n",
    "X_test_pre_spacy = tp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Prétraitement avec Gensim\n",
    "Utilisation de la méthode simple_preprocess, pour utiliser le prétraitement de Gensim dans les modèles il faut remplacer les varaibles ``X_train_pre_spacy`` et ``X_test_pre_spacy`` par ``X_train_pre_gen`` et ``X_test_pre_gen``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_gen = [' '.join(simple_preprocess(sentence)) for sentence in X_train ]\n",
    "X_test_pre_gen = [' '.join(simple_preprocess(sentence)) for sentence in X_test ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Modèle de machine learning avec TFidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Création des pipelines et entrainement des modeles\n",
    "Un pipeline est créé pour chaque type de modèle. Trois types de modèles ont été selectionné : \n",
    "\n",
    "* la régression linéaire\n",
    "* la machine à vecteur de support \n",
    "* la Foret aléatoire\n",
    "\n",
    "La classe TfidfVectorizer permet de calculer le score tfidf pour une phrase donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svr_model is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr_model is done\n"
     ]
    }
   ],
   "source": [
    "lr_model = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                    ('lr', LinearRegression(n_jobs=-1))])\n",
    "\n",
    "svr_model = Pipeline([('tfidf', TfidfVectorizer()),('svr', SVR(kernel='poly'))])\n",
    "\n",
    "rfr_model = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                    ('rfr', RandomForestRegressor(n_jobs=-1))])\n",
    "\n",
    "lr_model.fit(X_train_pre_spacy, y_train)\n",
    "print(\"lr_model is done\")\n",
    "svr_model.fit(X_train_pre_spacy, y_train)\n",
    "print(\"svr_model is done\")\n",
    "rfr_model.fit(X_train_pre_spacy, y_train)\n",
    "print(\"rfr_model is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Evaluation des modèles\n",
    "Le score des modèles est calculé avec le jeu de test. On remarque que pour la MAE et la RMSE seul le modèle Random Forest Regressor obtient de meilleurs résultats que les analyseurs preccedents. On peut également constater que la Random Forest Regressor obtient une bonne précison et un bon rappel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Linear regression : 0.5863239103350047\n",
      "MAE for Linear regression : 0.39035970502206513\n",
      "Accuracy for Linear regression : 0.7309734513274336\n",
      "Recall for Linear regression : 0.7458100558659218\n",
      "Precision for Linear regression : 0.8140243902439024\n",
      "\n",
      "\n",
      "RMSE for Support Vector Regression : 0.39891491103449844\n",
      "MAE for Support Vector Regression : 0.32363240415397093\n",
      "Accuracy for Support Vector Regression : 0.6336283185840708\n",
      "Recall for Support Vector Regression : 1.0\n",
      "Precision for Support Vector Regression : 0.6336283185840708\n",
      "\n",
      "\n",
      "RMSE for Random forest regressor : 0.28867546200058297\n",
      "MAE for Random forest regressor : 0.2050416997282776\n",
      "Accuracy for Random forest regressor : 0.8088495575221238\n",
      "Recall for Random forest regressor : 0.8575418994413407\n",
      "Precision for Random forest regressor : 0.8434065934065934\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = lr_model.predict(X_test_pre_spacy)\n",
    "print_scores('Linear regression', y_test, y_pred_lr)\n",
    "print(\"\\n\")\n",
    "y_pred_svr = svr_model.predict(X_test_pre_spacy)\n",
    "print_scores('Support Vector Regression', y_test, y_pred_svr)\n",
    "print(\"\\n\")\n",
    "y_pred_rfr = rfr_model.predict(X_test_pre_spacy)\n",
    "print_scores('Random forest regressor', y_test, y_pred_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3 Recherche aléatoire\n",
    "En plus d'optimiser les paramètres du modèle, la recherche alétoire entraine les modèles avec dans ce cas 15 folds. Ce qui va permettre de s'assurer que le modèle n'overfit pas trop. **Attention cette cellule prends beaucoup de temps à s'éxecuter (environ 30 minutes).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_random = {\n",
    "    'tfidf__use_idf' : (True, False),\n",
    "    'rfr__n_estimators' : [30, 100, 200, 400, 1000, 1200, 1500],\n",
    "    'rfr__max_features' : [2,4,6,8, 20, 100],\n",
    "    'rfr__bootstrap' : (True, False),\n",
    "    'rfr__max_depth' : [10, 30 , 50, 80, 100, None],\n",
    "    'rfr__min_samples_leaf': [1, 2, 4],\n",
    "    'rfr__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rfr_model_random = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                    ('rfr', RandomForestRegressor())])\n",
    "\n",
    "random_search_rfr = RandomizedSearchCV(rfr_model_random, param_grid_random,scoring='neg_mean_absolute_error', n_iter=50, verbose=1, cv=15, n_jobs=-1)\n",
    "random_search_rfr.fit(X_train_pre_spacy, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 Meilleurs paramètres de la recherche aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rfr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 Evaluation de la recherche aléatoire\n",
    "On constate qu'on obtient de meilleure résultats avec la recherche aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfr_random = random_search_rfr.predict(X_test_pre_spacy)\n",
    "print_scores('Random forest regressor - random search', y_test, y_pred_rfr_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(random_search_rfr, 'saved_model/headlines_dataset_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Modèle de machine learning avec d2v de Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Prétraitement du texte\n",
    "Pour envoyer les phrases au doc2vec il faut qu les mots sois placé dans une liste. On réeffectue le préprocessing sur le textes mais cette fois on met d'une phrases dans une liste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2 Spacy\n",
    "Le paramètre ``is_word_joined`` renvoie une liste de de liste(qui représente les mots de la phrase) au lieu d'une liste de string(qui représente la phrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_list = TextProcessor(is_word_joined=False, keep_only_good_word=False, remove_stop_word=True)\n",
    "X_train_pre_list_spacy = tp_list.fit_transform(X_train)\n",
    "X_test_pre_list_spacy = tp_list.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2 Gensim\n",
    "Utilisation de la méthode simple_preprocess, pour utiliser le prétraitement de Gensim dans les modèles il faut remplacer les varaibles ``X_train_pre_list_spacy`` et ``X_test_pre_list_spacy`` par ``X_train_pre_list_gen`` et ``X_test_pre_list_gen``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_list_gen = []\n",
    "for sentence in X_train:\n",
    "    X_train_pre_list_gen.append(simple_preprocess(sentence))\n",
    "    \n",
    "X_test_pre_list_gen = []\n",
    "for sentence in X_test:\n",
    "    X_test_pre_list_gen.append(simple_preprocess(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Création du doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2Vec_model =  D2VTransformer()\n",
    "doc2Vec_model.fit(X_train_pre_list_spacy+X_test_pre_list_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_d2v = doc2Vec_model.transform(X_train_pre_list_spacy)\n",
    "X_test_pre_d2v = doc2Vec_model.transform(X_test_pre_list_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les phrases sont transformées en vecteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Création des pipelines et entrainement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model_d2v = RandomForestRegressor(n_estimators=200, max_features=50)\n",
    "rfr_model_d2v.fit(X_train_pre_d2v, y_train)\n",
    "\n",
    "lr_model_d2v = LinearRegression()\n",
    "lr_model_d2v.fit(X_train_pre_d2v, y_train)\n",
    "\n",
    "svr_model_d2v = SVR(kernel='poly')\n",
    "svr_model_d2v.fit(X_train_pre_d2v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_pipeline_d2v = Pipeline([('d2v', doc2Vec_model),\n",
    "                     ('rfr', rfr_model_d2v)])\n",
    "\n",
    "lr_pipeline_d2v = Pipeline([('d2v', doc2Vec_model),\n",
    "                     ('rfr', lr_model_d2v)])\n",
    "\n",
    "svr_pipeline_d2v = Pipeline([('d2v', doc2Vec_model),\n",
    "                    ('svr', svr_model_d2v)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Évaluation des modèles\n",
    "Ces modèles ont en moyenne de moins bon résultats que les modèles préceddent. On remarque qu'en moyenne le rappel à augmenter sur tout les modèles et la précision diminué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfr_d2v = rfr_pipeline_d2v.predict(X_test_pre_list_spacy)\n",
    "print_scores('Random forest regressor', y_test, y_pred_rfr_d2v)\n",
    "print(\"\\n\")\n",
    "y_pred_lr_d2v = lr_pipeline_d2v.predict(X_test_pre_list_spacy)\n",
    "print_scores('Linear regression', y_test, y_pred_lr_d2v)\n",
    "print(\"\\n\")\n",
    "y_pred_svr_d2v = svr_pipeline_d2v.predict(X_test_pre_list_spacy)\n",
    "print_scores('Support Vector Regression', y_test, y_pred_svr_d2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 Entrainement du modèle avec la validation croisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfr_model_d2v, X_train_pre_d2v, y_train, scoring=\"neg_mean_absolute_error\", cv=15)\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Représentation T-sne \n",
    "Le T-sne permet de représenter les phrases du doc2vec dans l'espace. On constate que les phrases sont assez éparpillé et que les phrases postives ne sont pas regroupé avec les positives et inversement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0, verbose=1)\n",
    "X_2d_gen = tsne.fit_transform(np.concatenate((X_train_pre_d2v, X_test_pre_d2v), axis=0))\n",
    "\n",
    "X_component_gen = [item[0] for item in X_2d_gen]\n",
    "Y_component_gen = [item[1] for item in X_2d_gen]\n",
    "\n",
    "sent = [\"positive\" if sent>= 0 else \"negative\" for sent in (y_train.tolist() + y_test.tolist())]\n",
    "\n",
    "df_scatter_gen = pd.DataFrame({'x_component':X_component_gen, 'y_component':Y_component_gen, 'sentiment':sent})\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"2D sentence representation - Gensim preprocessing\")\n",
    "ax = sns.scatterplot(x='x_component', y='y_component', hue='sentiment', data=df_scatter_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(rfr_pipeline_d2v, 'saved_model/headlines_dataset_w2v.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. word2vec financier \n",
    "## 10.1 Importation du word2vec financier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'word2vec/financialWord2vec/src')\n",
    "from financial_corpus import FinancialCorpus\n",
    "from financial_w2vec import FinancialWord2Vec\n",
    "\n",
    "financial_w2vec = pickle.load(open('word2vec/financialWord2vec/data/models_pickle/FinancialWord2Vec.pkl','rb'))\n",
    "w2vec_model = financial_w2vec.model\n",
    "financial_corpus = financial_w2vec.financial_corpus\n",
    "\n",
    "bigram_mod = financial_corpus.bigram_mod\n",
    "trigram_mod = financial_corpus.bigram_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Nombres de mot présent dans le word2vec\n",
    "Cette cellule ne fonctionne que si le prétraitement du texte à été effectué avec Spacy et non gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2348 words in the word2vec on 4482 \n"
     ]
    }
   ],
   "source": [
    "nb_word_in_w2v = 0\n",
    "for w in tp.vocab:\n",
    "    if w in w2vec_model.wv.vocab:\n",
    "        nb_word_in_w2v+=1\n",
    "print(\"There are {} words in the word2vec on {} \".format(nb_word_in_w2v, len(tp.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Longeur maximum d'une phrase\n",
    "La longeur maximum nous permettera d'effectuer la technique du padding pour les vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum word in a sentence is : 25\n"
     ]
    }
   ],
   "source": [
    "max_sentence_length = 0\n",
    "for sentence in dataset[\"title\"]:\n",
    "    sentence_length = len(sentence.split())\n",
    "    if sentence_length > max_sentence_length:\n",
    "        max_sentence_length = sentence_length\n",
    "print(\"The maximum word in a sentence is : {}\".format(max_sentence_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 Calcul du Tf-idf\n",
    "Le score TF-idf est calculé sur le jeu de donnée et les scores sont exporté dans un dictionnaire avec comme clé le mot et comme valeur le score TF-idf de ce mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(X_train_pre_spacy+X_test_pre_spacy)\n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "word2tfidf = dict(zip(feature_names, tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 Définition des fonctions\n",
    "Definitions des différentes fonctions permettant de représenter une phrase dans l'espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_score(word):\n",
    "    '''Return the TF-idf score for a word. If the word is not in the dict return 0.\n",
    "    \n",
    "    word -- a word of a sentence\n",
    "    \n",
    "    return -- the TF-idf score for this word\n",
    "    '''\n",
    "    if word in word2tfidf:\n",
    "        return word2tfidf[word]\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_from_word(word, dimension=100):\n",
    "    '''Return the word2vec vector for the given word. \n",
    "    If the word is not in the word2vec vocab return a fille vector of 0 the size of the dimension\n",
    "    \n",
    "    word -- a word of a sentence\n",
    "    dimension -- the dimension of the vector\n",
    "    \n",
    "    return -- The word2vec vector\n",
    "    '''\n",
    "    if word in w2vec_model.wv.vocab: \n",
    "        doc = trigram_mod[bigram_mod[[word]]]\n",
    "        return w2vec_model.wv[doc][0]\n",
    "    else :\n",
    "        return np.zeros(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_w2v_big_vector(sentences, mode, dimension=100):\n",
    "    '''Transforms the list of passed sentences into a vector representation. The vectors here are concatenate.\n",
    "    For exemple : if the maximum sentence size is 25 and the dimension is 100. The number of vector component will be 2500.\n",
    "    \n",
    "    sentences -- list of preprocessed sentences\n",
    "    mode -- type of vectorial representation, 'concat' => concatene all the word vector in sequence,'concat_tfidf' => concatene the word vector and multiply by the tf-idf score of the word, \n",
    "    dimension -- the dimension of the vector\n",
    "\n",
    "    return -- the list of sentences in the space\n",
    "    '''\n",
    "    sentences_w2v = []\n",
    "    for sentence in sentences:  \n",
    "        \n",
    "        vectors = np.asarray([])\n",
    "        splited_sentence = sentence.split()\n",
    "        for i in range(0, max_sentence_length):\n",
    "            try :\n",
    "                word = splited_sentence[i]\n",
    "                w2v_word = get_w2v_from_word(word)\n",
    "                \n",
    "                if mode==\"concat_tfidf\":\n",
    "                    tfidf_score = get_tfidf_score(word)\n",
    "                    vectors = np.append(vectors, w2v_word*tfidf_score)\n",
    "                elif mode==\"concat\":\n",
    "                    vectors = np.append(vectors, w2v_word)\n",
    "                \n",
    "            except IndexError:\n",
    "                vectors = np.append(vectors, np.zeros(dimension))\n",
    "                \n",
    "        sentences_w2v.append(vectors)\n",
    "    return sentences_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_w2v_small_vector(sentences, mode, dimension=100):\n",
    "    '''Transforms the list of passed sentences into a vector representation. The vector is summed.\n",
    "    For exemple : if the maximum sentence size is 25 and the dimension is 100. The number of vector component will be 100.\n",
    "    \n",
    "    sentences - list of preprocessed sentences\n",
    "    mode -- type of vectorial representation, 'sum' => sum all the vector, 'sum_tfidf' => sum the vector and multiply each vector by tf_idf score, 'avg' => sum all the vector and divide by the sentence length, 'avg' => sum the vector, multiply each vector by tf_idf score and divide by sentence length\n",
    "    dimension -- the dimension of the vector\n",
    "    \n",
    "    return the list of sentences in the space\n",
    "    '''\n",
    "    sentences_w2v = []    \n",
    "    for sentence in sentences:\n",
    "        vectors = np.zeros(100)\n",
    "        \n",
    "        splited_sentence = sentence.split()\n",
    "        for word in splited_sentence:\n",
    "            w2v_word = get_w2v_from_word(word)\n",
    "            \n",
    "            if mode==\"sum_tfidf\" or mode==\"avg_tfidf\":\n",
    "                tfidf_score=get_tfidf_score(word)\n",
    "                vectors = np.add(vectors, w2v_word*tfidf_score)\n",
    "            elif mode==\"sum\" or mode==\"avg\":              \n",
    "                vectors = np.add(vectors, w2v_word)\n",
    "        \n",
    "        if mode==\"avg_tfidf\" or mode==\"avg\":    \n",
    "            if len(splited_sentence) != 0:\n",
    "                sentences_w2v.append(vectors/len(splited_sentence))\n",
    "            else :\n",
    "                sentences_w2v.append(np.zeros(dimension))\n",
    "        elif mode==\"sum\" or mode==\"sum_tfidf\":\n",
    "            sentences_w2v.append(vectors)\n",
    "    return np.asarray(sentences_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 Représentation des phrases dans l'espace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_pre_w2v = sentences_to_w2v_small_vector(X_train_pre_spacy, mode=\"avg\")\n",
    "X_test_pre_w2v = sentences_to_w2v_small_vector(X_test_pre_spacy, mode=\"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 Entrainement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finish for rfr\n",
      "training finish for lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finish for svr\n"
     ]
    }
   ],
   "source": [
    "rfr_model_w2v = RandomForestRegressor(n_estimators=100, max_features=50)\n",
    "rfr_model_w2v.fit(X_train_pre_w2v, y_train)\n",
    "print(\"training finish for rfr\")\n",
    "\n",
    "lr_model_w2v = LinearRegression()\n",
    "lr_model_w2v.fit(X_train_pre_w2v, y_train)\n",
    "print(\"training finish for lr\")\n",
    "\n",
    "svr_model_w2v = SVR(kernel='poly')\n",
    "svr_model_w2v.fit(X_train_pre_w2v, y_train)\n",
    "print(\"training finish for svr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.8 Calcul des scores\n",
    "Cette fois si la précison et le rappel sont meilleure qu'avec gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Random forest regressor : 0.3190806378668565\n",
      "MAE for Random forest regressor : 0.24678990371008297\n",
      "Accuracy for Random forest regressor : 0.768141592920354\n",
      "Recall for Random forest regressor : 0.8798882681564246\n",
      "Precision for Random forest regressor : 0.7816377171215881\n",
      "\n",
      "\n",
      "RMSE for Linear regression : 0.3387019255006186\n",
      "MAE for Linear regression : 0.27764543717593954\n",
      "Accuracy for Linear regression : 0.7610619469026548\n",
      "Recall for Linear regression : 0.8379888268156425\n",
      "Precision for Linear regression : 0.7957559681697612\n",
      "\n",
      "\n",
      "RMSE for Support Vector Regression : 0.36014613967523057\n",
      "MAE for Support Vector Regression : 0.269443533279749\n",
      "Accuracy for Support Vector Regression : 0.7592920353982301\n",
      "Recall for Support Vector Regression : 0.9217877094972067\n",
      "Precision for Support Vector Regression : 0.7534246575342466\n"
     ]
    }
   ],
   "source": [
    "y_pred_rfr_w2v = rfr_model_w2v.predict(X_test_pre_w2v)\n",
    "print_scores('Random forest regressor', y_test, y_pred_rfr_w2v)\n",
    "print(\"\\n\")\n",
    "y_pred_lr_w2v = lr_model_w2v.predict(X_test_pre_w2v)\n",
    "print_scores('Linear regression', y_test, y_pred_lr_w2v)\n",
    "print(\"\\n\")\n",
    "y_pred_svr_w2v = svr_model_w2v.predict(X_test_pre_w2v)\n",
    "print_scores('Support Vector Regression', y_test, y_pred_svr_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.9 Entrainement du modèle avec la validation croisé\n",
    "Au vu des scores MAE on voit que le moèdle n'overfit pas trop. La MAE est similaire à celle calculé préceddement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfr_model_w2v, X_train_pre_w2v, y_train, scoring=\"neg_mean_absolute_error\", cv=15)\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.10 Représentation T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0, verbose=1)\n",
    "X_2d_financial = tsne.fit_transform(np.concatenate((X_train_pre_w2v, X_test_pre_w2v), axis=0))\n",
    "\n",
    "X_component_financial = [item[0] for item in X_2d_financial]\n",
    "Y_component_financial = [item[1] for item in X_2d_financial]\n",
    "\n",
    "sent = [\"positive\" if sent>= 0 else \"negative\" for sent in (y_train.tolist() + y_test.tolist())]\n",
    "\n",
    "df_scatter_financial = pd.DataFrame({'x_component':X_component_financial, 'y_component':Y_component_financial, 'sentiment':sent})\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"2D sentence representation - personal preprocessing\")\n",
    "ax = sns.scatterplot(x='x_component', y='y_component', hue='sentiment', data=df_scatter_financial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Classificateur\n",
    "Entrainons maintenant uniquement des classificateurs. On commence par supprimer les phrases qui ont un sentiment compris entre -0.1 et 0.1 car ces phrases sont trop proches de 0 pour être classifié comme positive ou négative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data : 2594\n"
     ]
    }
   ],
   "source": [
    "index_to_remove = []\n",
    "for i, e in dataset.iterrows():\n",
    "    if e['sentiment'] < 0.1 and e['sentiment'] > -0.1:\n",
    "        index_to_remove.append(i)\n",
    "classification_data = dataset.drop(index_to_remove)\n",
    "print(\"size of data : {}\".format(len(classification_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Séparation des observations et étiquettes\n",
    "Les sentiments en dessous de 0 sont transformé en 0 et ceux en dessus de 0 en 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_classification = classification_data['title']\n",
    "y_classfication = np.array([1 if s > 0 else 0 for s in classification_data['sentiment']])\n",
    "X_train_classification, X_test_classification, y_train_classfication, y_test_classification = train_test_split(X_classification, y_classfication, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Prétraitement des phrases avec Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_gen_classification = [' '.join(simple_preprocess(sentence)) for sentence in X_train_classification ]\n",
    "    \n",
    "X_test_pre_gen_classification = [' '.join(simple_preprocess(sentence)) for sentence in X_test_classification ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Entrainement des modèles\n",
    "Les phrases sont converti en chiffre à l'aide de la technique du Tf-Idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                    ('nb', MultinomialNB())])\n",
    "\n",
    "svc_model = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('svc', SVC())])\n",
    "\n",
    "dtc_model = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "logr_model = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                    ('lr', LogisticRegression())])\n",
    "\n",
    "nb_model.fit(X_train_pre_gen_classification, y_train_classfication)\n",
    "svc_model.fit(X_train_pre_gen_classification, y_train_classfication)\n",
    "dtc_model.fit(X_train_pre_gen_classification, y_train_classfication)\n",
    "logr_model.fit(X_train_pre_gen_classification, y_train_classfication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Evaluation des modèles\n",
    "Execpté pour le DecisionTreeClassfifier on voit que le rappel est trop haut par rapport à la précision. Il faudrait donc ajuster le seuil pour diminuer le rappel et augmenter la précision. On constate cepandant que les modèles ont quand même un bon score d'exactitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes : 0.8015414258188824\n",
      "Precision for Naive Bayes : 0.7666666666666667\n",
      "Recall for Naive Bayes : 0.9847094801223242\n",
      "\n",
      "\n",
      "Accuracy for SVC : 0.630057803468208\n",
      "Precision for naive SVC : 0.630057803468208\n",
      "Recall for SVC : 1.0\n",
      "\n",
      "\n",
      "Accuracy for Decision Tree Classifier : 0.791907514450867\n",
      "Precision for Decision Tree Classifier : 0.8173913043478261\n",
      "Recall for Decision Tree Classifier : 0.8623853211009175\n",
      "\n",
      "\n",
      "Accuracy for Logistic Regression : 0.8323699421965318\n",
      "Precision for Logistic Regression : 0.8\n",
      "Recall for Decision Logistic Regression : 0.9785932721712538\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb = nb_model.predict(X_test_pre_gen_classification)\n",
    "print(\"Accuracy for Naive Bayes : {}\".format(metrics.accuracy_score(y_test_classification, y_pred_nb)))\n",
    "print(\"Precision for Naive Bayes : {}\".format(metrics.precision_score(y_test_classification, y_pred_nb)))\n",
    "print(\"Recall for Naive Bayes : {}\".format(metrics.recall_score(y_test_classification, y_pred_nb)))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_pred_svc = svc_model.predict(X_test_pre_gen_classification)\n",
    "print(\"Accuracy for SVC : {}\".format(metrics.accuracy_score(y_test_classification, y_pred_svc)))\n",
    "print(\"Precision for naive SVC : {}\".format(metrics.precision_score(y_test_classification, y_pred_svc)))\n",
    "print(\"Recall for SVC : {}\".format(metrics.recall_score(y_test_classification, y_pred_svc)))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_pred_dtc = dtc_model.predict(X_test_pre_gen_classification)\n",
    "print(\"Accuracy for Decision Tree Classifier : {}\".format(metrics.accuracy_score(y_test_classification, y_pred_dtc)))\n",
    "print(\"Precision for Decision Tree Classifier : {}\".format(metrics.precision_score(y_test_classification, y_pred_dtc)))\n",
    "print(\"Recall for Decision Tree Classifier : {}\".format(metrics.recall_score(y_test_classification, y_pred_dtc)))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_pred_logr = logr_model.predict(X_test_pre_gen_classification)\n",
    "print(\"Accuracy for Logistic Regression : {}\".format(metrics.accuracy_score(y_test_classification, y_pred_logr)))\n",
    "print(\"Precision for Logistic Regression : {}\".format(metrics.precision_score(y_test_classification, y_pred_logr)))\n",
    "print(\"Recall for Decision Logistic Regression : {}\".format(metrics.recall_score(y_test_classification, y_pred_logr)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_headlines = pd.read_excel(\"dataset/ppi_headlines/200_headlines_polarity.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ppi_headlines['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_index = []\n",
    "for index, row in ppi_headlines.iterrows():\n",
    "    if row[\"Polarisation\"] == \"positif\":\n",
    "        ppi_headlines.iloc[index][\"Polarisation\"] = 1\n",
    "    elif row[\"Polarisation\"] == \"négatif\":\n",
    "        ppi_headlines.iloc[index][\"Polarisation\"] = 0\n",
    "    elif row[\"Polarisation\"] == \"neutre\":\n",
    "        neutral_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_headlines = ppi_headlines.drop(neutral_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_pre = tp.fit_transform(ppi_headlines['Headline'])\n",
    "ppi_pre_vectors = sentences_to_w2v_small_vector(ppi_headlines['Headline'], mode=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ppi = rfr_model_w2v.predict(ppi_pre_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ppi = regression_score_to_classification(y_pred_ppi, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ppi = ppi_headlines[\"Polarisation\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for PPI Headlines : 0.5223880597014925\n",
      "Precision for PPI Headlines : 0.5\n",
      "Recall for PPI Headlines : 0.53125\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for PPI Headlines : {}\".format(metrics.accuracy_score(y_test_ppi, y_pred_ppi)))\n",
    "print(\"Precision for PPI Headlines : {}\".format(metrics.precision_score(y_test_ppi, y_pred_ppi)))\n",
    "print(\"Recall for PPI Headlines : {}\".format(metrics.recall_score(y_test_ppi, y_pred_ppi)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
